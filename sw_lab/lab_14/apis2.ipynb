{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Denison DA210/CS181 SW Lab #14 - Step 1\n",
    "\n",
    "Before you get your checkpoints, make sure everything runs as expected. This is a combination of **restarting the kernel** and then **running all cells**.\n",
    "\n",
    "Make sure you fill in any place that says `# YOUR CODE HERE` or \"YOUR ANSWER HERE\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import sys\n",
    "import importlib\n",
    "import io\n",
    "import pandas as pd\n",
    "from lxml import etree\n",
    "\n",
    "module_dir = \"../../modules\"\n",
    "module_path = os.path.abspath(module_dir)\n",
    "if not module_path in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import util\n",
    "importlib.reload(util)\n",
    "\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part A: High-Level Planning\n",
    "\n",
    "We can use the GitHub API to retrieve information about organizations, repositories, and users.  Even without authenticating, we can find the commits and users that have made changes to specific files in a repository.\n",
    "\n",
    "With this goal in mind, we will divide our work into two phases:\n",
    "* Build a table of commits to a specific file.\n",
    "* Build a table of users who have modified that file.  \n",
    "\n",
    "Both of these two phases can be further divided into several steps:\n",
    "1. Understand the API endpoint.  \n",
    "2. Design a function to issue our requests.  \n",
    "3. Design the commit table (data frame).  \n",
    "4. [If necessary] Handle multiple pages.\n",
    "\n",
    "To accomplish our overall goals, we'll make use of two GitHub API endpoints:\n",
    "* [/repos/{owner}/{repo}/commits](https://docs.github.com/en/rest/commits/commits#list-commits)\n",
    "* [/users/{username}](https://docs.github.com/en/rest/users/users#get-a-user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f2fd93d0e89b10bade86cff95b35d739",
     "grade": true,
     "grade_id": "cell-125cbee27c447392",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Part B: Building a table of commits to a specific file\n",
    "\n",
    "We'll try to gather information about the `pandas` repository on GitHub, specifically looking at changes to the `groupby.py` file.  Here is its [file docstring](https://github.com/pandas-dev/pandas/blob/main/pandas/core/groupby/groupby.py):\n",
    "\n",
    "```\n",
    "    \"\"\"\n",
    "    Provide the groupby split-apply-combine paradigm. Define the GroupBy\n",
    "    class providing the base-class of operations.\n",
    "\n",
    "    The SeriesGroupBy and DataFrameGroupBy sub-class\n",
    "    (defined in pandas.core.groupby.generic)\n",
    "    expose these user-facing objects to provide specific functionality.\n",
    "    \"\"\"\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Understand the `list-commits` API endpoint\n",
    "\n",
    "We can use the list-commits endpoint to query information about this file.  First, let's explore the results we get from this endpoint.\n",
    "\n",
    "We can view the commits for this file on GitHub: https://github.com/pandas-dev/pandas/commits/main/pandas/core/groupby/groupby.py.\n",
    "\n",
    "Also, as this is a GET request, we can view the general version (without query parameters) in a web browser to get a feel for the results: https://api.github.com/repos/pandas-dev/pandas/commits.  (Firefox in particular has a very nice view of the headers, raw JSON data, and parsed JSON result.)\n",
    "\n",
    "The endpoint documentation tells us we'll need to specify the filepath (relative within the repo) as a _query parameter_.  Let's try out a request:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the URL\n",
    "host = \"api.github.com\"\n",
    "resource_path = f\"/repos/pandas-dev/pandas/commits\"\n",
    "url = util.buildURL(resource_path, host, protocol=\"https\")\n",
    "\n",
    "# Make the request\n",
    "query_params = {\"path\": \"pandas/core/groupby/groupby.py\"}\n",
    "try:\n",
    "    response = requests.get(url, params=query_params)\n",
    "    assert response.status_code == 200\n",
    "except AssertionError:\n",
    "    print(f\"Failed: {resource_path} with status code {response.status_code}\")\n",
    "\n",
    "# Display the parsed JSON object\n",
    "data = response.json()\n",
    "util.print_json(data, level=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8c5aa5f46db2ef30705092d581601525",
     "grade": false,
     "grade_id": "cell-7af55ab11001c5ef",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "#### Step 2: Design a function to issue a request\n",
    "\n",
    "Next, we can write a function to enable more programmatic access to this endpoint, and provide some abstraction between the endpoint parameters and how the request is made.\n",
    "\n",
    "**Q1:** Write a function `getRepositoryCommitsSimple(owner, repo, path)` to access the [list-commits](https://docs.github.com/en/rest/commits/commits#list-commits) endpoint (the one from the example above) for a given path within a repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f2fd93d0e89b10bade86cff95b35d739",
     "grade": true,
     "grade_id": "cell-125cbee27c447392",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Example using list-commits endpoint\n",
    "owner = \"pandas-dev\"\n",
    "repo = \"pandas\"\n",
    "query_path = \"pandas/core/groupby/groupby.py\"\n",
    "data = getRepositoryCommitsSimple(owner, repo, query_path)\n",
    "\n",
    "util.print_json(data, level=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [GitHub documentation](https://docs.github.com/en/rest/commits/commits#list-commits) shows that this result should be a JSON array (corresponding to a Python list) of JSON objects (Python dictionaries).  There are at most 30 (by default) objects per \"page\", and each object should represent a single commit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many commits' info we got\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the most recent commit's info\n",
    "commit_obj = data[0]\n",
    "util.print_json(commit_obj, level=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the most recent commit's message\n",
    "commit_obj[\"commit\"][\"message\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the most recent commit's timestamp\n",
    "commit_obj[\"commit\"][\"author\"][\"date\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Design commit table\n",
    "\n",
    "We'll collect the following information about each commit:\n",
    "- commit ID\n",
    "- message\n",
    "- commiter username\n",
    "- commit timestamp\n",
    "\n",
    "We can write a function that produces a list of row dictionaries (LoD) representation from the JSON-parsed data structure of a request.  This is provided for you, below.  Take a look through it and make sure you understand where the pieces are coming from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def commitResult2LoD(result, maxelements=None):\n",
    "    \"\"\"\n",
    "    Build an LoD from a JSON result from the GitHub list-commits API endpoint.\n",
    "    \"\"\"\n",
    "    assert isinstance(result, list)\n",
    "\n",
    "    LoD = []\n",
    "    count = 0\n",
    "    for commit_obj in result:\n",
    "        if maxelements != None and count >= maxelements:\n",
    "            break\n",
    "\n",
    "        D = {}\n",
    "        D[\"id\"] = commit_obj[\"sha\"]\n",
    "        D[\"message\"] = commit_obj[\"commit\"][\"message\"]\n",
    "        D[\"author\"] = commit_obj[\"author\"][\"login\"]\n",
    "        D[\"timestamp\"] = commit_obj[\"commit\"][\"author\"][\"date\"]\n",
    "        LoD.append(D)\n",
    "\n",
    "        count += 1\n",
    "\n",
    "    return LoD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try parsing the commit results from our previous request\n",
    "LoD = commitResult2LoD(data)\n",
    "for row in LoD[:3]:\n",
    "    util.print_data(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Handle multiple pages\n",
    "\n",
    "API service providers often throttle results to avoid sending too much data at once.  The results are typically divided into _chunks_, or _pages_, and the request must specify the desired page and/or the desired number of results per page.  Then, it is up to the client to navigate this, and issue additional requests if necessary, until the desired amount of data is acquired.\n",
    "\n",
    "If we want more than 30 results (the default page size for the list-commit endpoint), or if we want a later page of results, we can add additional parameters, as outlined in the GitHub API documentation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You've reached the first checkpoint in the lab.  Make sure to have it signed off by the instructor or TA.\n",
    ">\n",
    "> Checkpoint 1: Take a look at the [list-commits endpoint documentation](https://docs.github.com/en/rest/commits/commits#list-commits).  How can you specify the number of results per page, and the page to retrieve?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2:** Write a new function `getRepositoryCommitsByPage(owner, repo, path, num_per_page=10, page=1)` that requests one _page_ of `num_per_page` results from the list-commits endpoint.  Using the `page` parameter will allow us to easily programmatically request different pages of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example using list-commits endpoint\n",
    "owner = \"pandas-dev\"\n",
    "repo = \"pandas\"\n",
    "query_path = \"pandas/core/groupby/groupby.py\"\n",
    "data = getRepositoryCommitsByPage(owner, repo, query_path, page=2)\n",
    "\n",
    "util.print_json(data, level=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will make use of this new function to make several requests.  We do so in `getCommits(owner, repo, query_path, num_commits)`, below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCommits(owner, repo, query_path, num_commits=15, num_per_page=10):\n",
    "    \"\"\"\n",
    "    Retrieve up to num_commits commits for a given filepath in a GitHub repo,\n",
    "    in pages of num_per_page commits at a time.\n",
    "    \"\"\"\n",
    "    fullLoD = []\n",
    "\n",
    "    page = 1\n",
    "    commits_left = num_commits\n",
    "    more_pages = True\n",
    "\n",
    "    while more_pages and commits_left > 0:\n",
    "        commit_page = getRepositoryCommitsByPage(owner, repo, query_path, num_per_page, page)\n",
    "\n",
    "        if len(commit_page) < num_per_page:\n",
    "            more_pages = False\n",
    "\n",
    "        pageLoD = commitResult2LoD(commit_page)\n",
    "        fullLoD.extend(pageLoD)\n",
    "\n",
    "        commits_left -= len(pageLoD)\n",
    "        page += 1\n",
    "\n",
    "    df = pd.DataFrame(fullLoD)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a table of commits\n",
    "num_commits = 12\n",
    "num_per_page = 8\n",
    "commits_df = getCommits(owner, repo, query_path, num_commits, num_per_page)\n",
    "\n",
    "print(\"Number of commits in DataFrame:\", len(commits_df))\n",
    "commits_df.iloc[:5, :]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You've reached the second checkpoint in the lab.  Make sure to have it signed off by the instructor or TA.\n",
    ">\n",
    "> Checkpoint 2: Look at the code for `getCommits`.  Why do we use `fullLoD.extend()` instead of `fullLoD.append()`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part C: Building a table of users who modified the file\n",
    "\n",
    "Given the set of author usernames from the previous part, we can build a table of user information for those users.  This will involve multiple requests, one per user, to obtain information about each user.  From this, we can build a table and remove any duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Understand `users` API endpoint\n",
    "\n",
    "First, we'll need to understand the `users` API endpoint.  Here is the documentation: https://docs.github.com/en/rest/users/users#get-a-user.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3:** Write a function `getUser(username)` to make a request to the `users` endpoint for a given GitHub username.  Your function should return the parsed `JSON` object of the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look up one of the people in the pandas-dev org\n",
    "# (https://github.com/orgs/pandas-dev/people)\n",
    "user1 = getUser(\"cpcloud\")\n",
    "util.print_json(user1, level=1, maxchildren=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Understand the results\n",
    "\n",
    "Let's look at the documentation regarding the results for requests to this endpoint:\n",
    "- The root of the returned value (JSON object).\n",
    "- The root has lots of children, including: `\"login\"`, `\"type\"`, `\"company\"`, `\"name\"`, and `\"email\"`.\n",
    "- Each of the values of these children is a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the user's name, if provided\n",
    "user1[\"name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the user's email, if provided\n",
    "print(user1[\"email\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Design users table\n",
    "\n",
    "To build a tabular representation of GitHub users, we need to decide on the fields.  For simplicity, we'll specify just four fields:\n",
    "\n",
    "| Field     | Python type | Notes |\n",
    "| --------- | ----------- | ----- |\n",
    "| `username`   | `str`       | The GitHub username of the user |\n",
    "| `name`    | `str`       | The name of the user |\n",
    "| `location`   | `str`       | The location of the user |\n",
    "| `company` | `str`       | The company of the user |\n",
    "\n",
    "**Q4:** Write a function `getUserRow(user)` to return a dictionary containing these values for a given user object returned from the `users` endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try this out\n",
    "getUserRow(user1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test that it's working\n",
    "user1_row = getUserRow(user1)\n",
    "\n",
    "assert user1_row[\"username\"] == \"cpcloud\"\n",
    "assert user1_row[\"name\"] == \"Phillip Cloud\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5:** Using these functions, we can build the full list of users given a list of usernames.  Write a function `getUsers(usernames)` that takes a list of usernames (as strings), and for each username, queries the `user` GitHub API endpoint, then uses `getUserRow` to build a dictionary for that user with just the fields we care about.  Finally, your function should build a `pandas DataFrame` of the resulting data.\n",
    "\n",
    "Note: Make sure to remove duplicates, ideally before making API requests, or at least from your resulting `DataFrame` (using the function `drop_duplicates`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the function `getUsers` we can now use the usernames of those who authored commits to the `pandas` repository to build a `DataFrame` of those users' information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the users DataFrame\n",
    "usernames = list(commits_df[\"author\"])\n",
    "users_df = getUsers(usernames)\n",
    "\n",
    "print(\"Number of users in DataFrame:\", len(users_df))\n",
    "users_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You've reached the third checkpoint in the lab.  Make sure to have it signed off by the instructor or TA.\n",
    ">\n",
    "> Checkpoint 3: Why is it important to remove duplicates from the Users table?  Reference both performance and tidy data assumptions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "We created two DataFrames, one for commit info for a given file, and another for the users involved in those commits.  The two DataFrames are shown again below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commits_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> You've reached the fourth (and final) checkpoint in the lab.  Make sure to have it signed off by the instructor or TA.\n",
    ">\n",
    "> Checkpoint 4: If you run this notebook too often, you start getting a `403` status code for all requests.  Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "---\n",
    "\n",
    "## Part D\n",
    "\n",
    "How much time (in minutes/hours) did you spend on this lab outside of class?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
